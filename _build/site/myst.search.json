{"version":"1","records":[{"hierarchy":{"lvl1":"AI Methods for Materials Science"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"AI Methods for Materials Science"},"content":"This course covers an introduction of topics and tools which serve as the basic for data modeling in materials science. The course aims to cover from supervised learning for property prediction, image recognition and graph-based models to introductory unsupervised algorithms for data compression and reconstruction.  The course assumes a basic knowledge of Python, specifically Numpy, Pandas, Scipy, and Matplotlib.\n\nThe outline of the course can be found \n\n","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"AI Methods for Materials Science","lvl2":"What this course covers"},"type":"lvl2","url":"/#what-this-course-covers","position":2},{"hierarchy":{"lvl1":"AI Methods for Materials Science","lvl2":"What this course covers"},"content":"How modern machine learning and statistical methods accelerate materials discovery.\n\nData pipelines: curation, featurization, and validation for chemistry and materials datasets.\n\nCore models: linear baselines, tree ensembles, Gaussian processes, and neural networks.\n\nGenerative and surrogate modeling for structure/property exploration.\n\nAutomation: connecting ML with simulation workflows and labs.\n\nResponsible AI: reproducibility, uncertainty, and ethics in scientific AI.","type":"content","url":"/#what-this-course-covers","position":3},{"hierarchy":{"lvl1":"AI Methods for Materials Science","lvl2":"How to use this template"},"type":"lvl2","url":"/#how-to-use-this-template","position":4},{"hierarchy":{"lvl1":"AI Methods for Materials Science","lvl2":"How to use this template"},"content":"Update _config.yml and myst.yml with author, logo, and repository links.\n\nAdd or reorder chapters in _toc.yml.\n\nReplace module pages in modules/ with your lecture notes or notebooks.\n\nRun myst start or myst build to preview locally.","type":"content","url":"/#how-to-use-this-template","position":5},{"hierarchy":{"lvl1":"AI Methods for Materials Science","lvl2":"Quick links"},"type":"lvl2","url":"/#quick-links","position":6},{"hierarchy":{"lvl1":"AI Methods for Materials Science","lvl2":"Quick links"},"content":"Syllabus\n\nResources\n\n","type":"content","url":"/#quick-links","position":7},{"hierarchy":{"lvl1":"Liner models"},"type":"lvl1","url":"/linear-models","position":0},{"hierarchy":{"lvl1":"Liner models"},"content":"\n\nimport numpy as np\n\n\n\n","type":"content","url":"/linear-models","position":1},{"hierarchy":{"lvl1":"Resources"},"type":"lvl1","url":"/resources","position":0},{"hierarchy":{"lvl1":"Resources"},"content":"","type":"content","url":"/resources","position":1},{"hierarchy":{"lvl1":"Resources","lvl2":"Core Books"},"type":"lvl2","url":"/resources#core-books","position":2},{"hierarchy":{"lvl1":"Resources","lvl2":"Core Books"},"content":"Pattern Recognition and Machine Learning, C. M. Bishop.\n\nProbabilistic Machine Learning: An Introduction, K. P. Murphy.\n\nDeep Learning for Molecules & Materials, A. D. White.","type":"content","url":"/resources#core-books","position":3},{"hierarchy":{"lvl1":"Resources","lvl2":"Datasets to explore"},"type":"lvl2","url":"/resources#datasets-to-explore","position":4},{"hierarchy":{"lvl1":"Resources","lvl2":"Datasets to explore"},"content":"Materials Project (crystal structures and properties).\n\nOQMD (formation energies).\n\nOC20/OC22 (catalysis).\n\nQM9 (small molecules), PCQM4Mv2 (graph-based property prediction).\n\nAFLOW, NOMAD, or any in-house datasets with clear licenses. ## Reading list (starter)\n\n- Butler et al., *Machine Learning for Molecular and Materials Science* (2018).\n- Schmidt et al., *Recent Advances and Applications of Machine Learning in Solid-State Materials Science* (2019).\n- Xie & Grossman, *Crystal Graph Convolutional Neural Networks for an Accurate and Interpretable Prediction of Material Properties* (2018).\n- Kingma & Welling, *Auto-Encoding Variational Bayes* (2013) — for generative modeling background.\n- Rasmussen & Williams, *Gaussian Processes for Machine Learning* (2006).  ## Tips for running the course\n\n- Keep every notebook executable from a clean environment; pin dependencies.\n- Include small “toy” datasets for in-class demos; link to large datasets for homework.\n- Encourage students to log experiments (hyperparameters, seeds, metrics).\n- Set up a shared glossary for key terms and symbols.\n ","type":"content","url":"/resources#datasets-to-explore","position":5},{"hierarchy":{"lvl1":"Syllabus"},"type":"lvl1","url":"/syllabus","position":0},{"hierarchy":{"lvl1":"Syllabus"},"content":"","type":"content","url":"/syllabus","position":1},{"hierarchy":{"lvl1":"Syllabus","lvl2":"Course overview"},"type":"lvl2","url":"/syllabus#course-overview","position":2},{"hierarchy":{"lvl1":"Syllabus","lvl2":"Course overview"},"content":"This course introduces practical AI tools for materials science, blending lectures with hands-on notebooks. Students will learn to frame scientific questions as machine learning and data science tasks, build reliable models, and integrate them with simulation or experimental pipelines.","type":"content","url":"/syllabus#course-overview","position":3},{"hierarchy":{"lvl1":"Syllabus","lvl2":"Learning objectives"},"type":"lvl2","url":"/syllabus#learning-objectives","position":4},{"hierarchy":{"lvl1":"Syllabus","lvl2":"Learning objectives"},"content":"Formulate materials problems for supervised, and unsupervised.\n\nEngineer features for molecules, crystals, and microstructures.\n\nTrain, tune, and evaluate models.\n\nCommunicate results with reproducible workflows and documentation.","type":"content","url":"/syllabus#learning-objectives","position":5},{"hierarchy":{"lvl1":"Syllabus","lvl2":"Schedule"},"type":"lvl2","url":"/syllabus#schedule","position":6},{"hierarchy":{"lvl1":"Syllabus","lvl2":"Schedule"},"content":" Week 1: ML foundations for scientific data  \nWeek 2: Data pipelines and featurization  \nWeek 3: Linear models, trees, and GPs  \nWeek 4: Neural networks for materials data  \nWeek 5: Generative models for structure/property exploration  \nWeek 6: Active learning and Bayesian optimization  \nWeek 7: Automation with simulation workflows  \nWeek 8: Ethics, reproducibility, and project presentations \n\nWeek 1: Linear models\n\nWeek 2: Kernel models\n\nWeek 3: Neural Networks\n\nWeek 4: Gradient descent and differentiable programming\n\nWeek 5: Molecular representations\n\nWeek 6: Graph Neural networks\n\nWeek 7: Reading week break. No classes this week!!\n\nWeek 8: MACE or PySCF tutorial","type":"content","url":"/syllabus#schedule","position":7},{"hierarchy":{"lvl1":"Syllabus","lvl2":"Final project"},"type":"lvl2","url":"/syllabus#final-project","position":8},{"hierarchy":{"lvl1":"Syllabus","lvl2":"Final project"},"content":"Due to the length of the course, the grading will be based on a final project that includes three parts.\n\nWritten Report, 4 Pages maximum\n\nPage 1: Introduction\n\nPage 2: Methodology\n\nPages 3-4: Results, Discussion and Summary.\n\nExtra pages include references, and additional data and results.\n\nOral Presentation, 20 min maximum\n\n20 min long.\n\nClearly state what is the goal of the project\n\nMethodology description\n\nSome results discussion\n\nConclusion\n\nCode\n\nJupyter notebook file (.ipynb) deployable in Google Colab.\n\nIt should run smoothly and self-explanatory for other students.","type":"content","url":"/syllabus#final-project","position":9}]}